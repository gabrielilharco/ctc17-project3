{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Movie Rates with Decision Tree\n",
    "\n",
    "In this report, we are building step by step a decision tree to predict user ratings on movies using the MovieLens dataset, available at http://grouplens.org/datasets/movielens/\n",
    "\n",
    "The dataset is composed by 3 main files:\n",
    "\n",
    "**movies.dat:** this file contains information of all movies, in the format < movie id > :: < movie name > :: < pipe separeted list of genders >\n",
    "\n",
    "**users.dat:** this file contains information of all users, in the format < user id > :: < user gender > :: < user age > :: < ocupation > :: < zip code > \n",
    "\n",
    "**ratings.dat:** this file contains information of all ratings, in the format < user id > :: < movie id > :: < rating > :: < timestamp >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data\n",
    "\n",
    "The first step in this project is to join the data in the 3 data files into a feature and a label matrices. For the gender informations, for each movie we added a binary variable for each different gender. \n",
    "\n",
    "The function **build_features** does all the processing, and returns two matrices, X and y, corresponding to the features and the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>ocupation</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating gender  age ocupation Action Adventure Animation Children's Comedy  \\\n",
       "0       5      F    1        10  False     False     False      False  False   \n",
       "1       5      M   56        16  False     False     False      False  False   \n",
       "2       4      M   25        12  False     False     False      False  False   \n",
       "3       4      M   25         7  False     False     False      False  False   \n",
       "4       5      M   50         1  False     False     False      False  False   \n",
       "\n",
       "  Documentary   ...   Fantasy Film-Noir Horror Musical Mystery Romance Sci-Fi  \\\n",
       "0       False   ...     False     False  False   False   False   False  False   \n",
       "1       False   ...     False     False  False   False   False   False  False   \n",
       "2       False   ...     False     False  False   False   False   False  False   \n",
       "3       False   ...     False     False  False   False   False   False  False   \n",
       "4       False   ...     False     False  False   False   False   False  False   \n",
       "\n",
       "  Thriller    War Western  \n",
       "0    False  False   False  \n",
       "1    False  False   False  \n",
       "2    False  False   False  \n",
       "3    False  False   False  \n",
       "4    False  False   False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def build_features():\n",
    "    \"\"\"\n",
    "    read data from movies, users and rating and return a single pandas dataframe\n",
    "    of the joined tables, containing all info on ratings\n",
    "    \"\"\"\n",
    "    # movie genres\n",
    "    genres = [\n",
    "        'Action',\n",
    "        'Adventure',\n",
    "        'Animation',\n",
    "        'Children\\'s',\n",
    "        'Comedy',\n",
    "        'Documentary',\n",
    "        'Drama',\n",
    "        'Fantasy',\n",
    "        'Film-Noir',\n",
    "        'Horror',\n",
    "        'Musical',\n",
    "        'Mystery',\n",
    "        'Romance',\n",
    "        'Sci-Fi',\n",
    "        'Thriller',\n",
    "        'War',\n",
    "        'Western'\n",
    "    ]\n",
    "    # reading movies data\n",
    "    movies_df = pd.DataFrame(columns=['movie_id'] + genres)\n",
    "    with open('../data/movies.dat','r') as file:\n",
    "        \n",
    "        \n",
    "        lines = file.readlines()\n",
    "        for idx in range(len(lines)):\n",
    "            row = lines[idx].split(\"::\")\n",
    "            movie_genres = row[-1][:-1].split('|')\n",
    "            row = row[:-2] # ignore genre and movie name\n",
    "            for genre in genres:\n",
    "                row.append(str(genre in movie_genres))\n",
    "            movies_df.loc[idx] = row\n",
    "    \n",
    "    # reading users data\n",
    "    users_df = pd.read_table('../data/users.dat', \n",
    "                    names=['user_id', 'gender', 'age', 'ocupation', 'zip_code'], \n",
    "                     sep='::', engine='python')\n",
    "    users_df['user_id'] = users_df['user_id'].apply(lambda x: str(x))\n",
    "    users_df['ocupation'] = users_df['ocupation'].apply(lambda x: str(x))\n",
    "    \n",
    "    # reading ratings data\n",
    "    ratings_df = pd.read_table('../data/ratings.dat', \n",
    "                    names=['user_id', 'movie_id', 'rating', 'timestamp'], \n",
    "                    sep='::', engine='python')\n",
    "    ratings_df['movie_id'] = ratings_df['movie_id'].apply(lambda x: str(x))\n",
    "    ratings_df['user_id'] = ratings_df['user_id'].apply(lambda x: str(x))\n",
    "    \n",
    "    # join tables\n",
    "    user_ratings_df = ratings_df.merge(users_df, how='inner', on='user_id')\n",
    "    features_df = user_ratings_df.merge(movies_df, how='inner', on='movie_id')\n",
    "    \n",
    "    # drop unwanted features\n",
    "    features_df = features_df.drop('timestamp', 1)\n",
    "    features_df = features_df.drop('zip_code', 1)\n",
    "    features_df = features_df.drop('user_id', 1)\n",
    "    features_df = features_df.drop('movie_id', 1)\n",
    "   \n",
    "    # print first 5 rows\n",
    "    display(features_df.head()) \n",
    "    \n",
    "    return features_df\n",
    "    \n",
    "data = build_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Tree\n",
    "\n",
    "\n",
    "#### Splitting the dataset\n",
    "\n",
    "Now we are going to build the decision tree. To do so, a good start is to create a method that, given some data rows, a feature and a value, splits the data into two disjoint subsets, according to the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_df(df, feature, value):\n",
    "    \"\"\"\n",
    "    splits a data frame in two separate subsets: \n",
    "    one where all rows have row[feature] >= value for ints or floats and row[feature] == value for strings\n",
    "    and another one where all rows have row[feature] < value for ints or floats and row[feature] != value for strings \n",
    "    \"\"\"\n",
    "    if isinstance(value,int) or isinstance(value,float):\n",
    "        df1 = df.ix[df[feature] >= value]\n",
    "        df2 = df.ix[df[feature] < value]\n",
    "    else:\n",
    "        df1 = df.ix[df[feature] == value]\n",
    "        df2 = df.ix[df[feature] != value]\n",
    "        \n",
    "    return df1, df2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting labels\n",
    "\n",
    "We now construct a function to, given a dataframe, count how many rows are there of each label, which will be usefull for determining the nodes of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    348971\n",
      "3    261197\n",
      "5    226310\n",
      "2    107557\n",
      "1     56174\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def label_counts(df, label_name):\n",
    "    \"\"\"\n",
    "    returns the count of each label value\n",
    "    \"\"\"\n",
    "    return df[label_name].value_counts()\n",
    "    \n",
    "print label_counts(data, 'rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entropy\n",
    "\n",
    "We need to create a method for evaluating the homogenity of the set. We will use the standard entropy function for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1002315644\n"
     ]
    }
   ],
   "source": [
    "from math import log \n",
    "log2 = lambda x: log(x)/log(2)\n",
    "\n",
    "def entropy(df, label_name):\n",
    "    \"\"\"\n",
    "    returns the entropy in a dataset\n",
    "    \"\"\"\n",
    "    s = 0.0\n",
    "    if len(df.index) == 0:\n",
    "        return s\n",
    "    \n",
    "    counts = label_counts(df, label_name)\n",
    "    size = len(df.index)\n",
    "    for _, count in counts.iteritems():\n",
    "        p = float(count)/size\n",
    "        s -= p*log2(p)\n",
    "    return s\n",
    "\n",
    "print entropy(data, 'rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the tree\n",
    "\n",
    "Now we start creating the tree. We use a recursive approach, building a node which maximizes the information gain at each step. Note that a node is represented by two attributes: the name of the feature and a value. These variables are passed as parameters to the  split_df method above written, dividing the dataset into two disjoint subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class node:\n",
    "    \"\"\"\n",
    "    Tree node\n",
    "    \"\"\"\n",
    "    def __init__(self, feature, value, counts, true_node=None, false_node=None):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.true_node = true_node\n",
    "        self.false_node = false_node\n",
    "        self.counts = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_best_criteria(df, label_name):\n",
    "    \"\"\"\n",
    "    build a node with a feature and a value \n",
    "    that maximizes information gain for the given dataframe\n",
    "    \"\"\"\n",
    "    # initial variables\n",
    "    best_criteria = (None, None)\n",
    "    best_gain = 0.0\n",
    "    best_sets = (None, None)\n",
    "    current_entropy = entropy(df, label_name)\n",
    "    \n",
    "    # iterate through all possible choices and select the one with the biggest information gain\n",
    "    for feature in df.columns.values:\n",
    "        if feature != label_name:\n",
    "            values = df[feature].unique()\n",
    "            for value in values:\n",
    "                df1, df2 = split_df(df, feature, value)\n",
    "                p = float(len(df1.index))/len(df.index)\n",
    "                gain = current_entropy-p*entropy(df1, label_name)-(1-p)*entropy(df2, label_name)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_criteria = (feature, value)\n",
    "                    best_sets = (df1, df2)\n",
    "    return best_criteria, best_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tree. This may take a while...\n"
     ]
    }
   ],
   "source": [
    "def build_tree(df, label_name, max_depth=None):\n",
    "    \"\"\"\n",
    "    build the decision tree\n",
    "    \"\"\"\n",
    "    if len(df.index) == 0 or max_depth == 0:\n",
    "        return None\n",
    "    (feature,value), (df1, df2) = find_best_criteria(df, label_name)\n",
    "    if feature is None or value is None:\n",
    "        return None\n",
    "    new_depth = None if max_depth is None else max_depth-1\n",
    "    true_node = build_tree(df1, label_name, new_depth)\n",
    "    false_node = build_tree(df2, label_name, new_depth)\n",
    "    return node(feature, value, label_counts(df, label_name), true_node, false_node)\n",
    "\n",
    "print \"Building tree. This may take a while...\"\n",
    "decision_tree = build_tree(data, 'rating', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying the tree\n",
    "\n",
    "Now we build a visualization method for displaying the tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drama == False ?\n",
      "T: Film-Noir == False ?\n",
      "   T: Horror == False ?\n",
      "      T: age >= 35 ?\n",
      "         T: War == False ?\n",
      "         F: Animation == True ?\n",
      "      F: Action == False ?\n",
      "         T: Comedy == True ?\n",
      "         F: Thriller == True ?\n",
      "   F: Adventure == True ?\n",
      "      T: ocupation == 1 ?\n",
      "         T: age >= 25 ?\n",
      "         F: ocupation == 2 ?\n",
      "      F: Thriller == False ?\n",
      "         T: age >= 25 ?\n",
      "         F: Sci-Fi == True ?\n",
      "F: War == False ?\n",
      "   T: age >= 35 ?\n",
      "      T: age >= 50 ?\n",
      "         T: Romance == True ?\n",
      "         F: Romance == False ?\n",
      "      F: Romance == False ?\n",
      "         T: Horror == False ?\n",
      "         F: Adventure == True ?\n",
      "   F: Thriller == True ?\n",
      "      T: Action == False ?\n",
      "         T: ocupation == 17 ?\n",
      "         F: age >= 50 ?\n",
      "      F: Comedy == True ?\n",
      "         T: age >= 35 ?\n",
      "         F: Western == True ?\n"
     ]
    }
   ],
   "source": [
    "def print_tree(tree,indent=''):\n",
    "    \"\"\"\n",
    "    print a decision tree\n",
    "    \"\"\"\n",
    "    if isinstance(tree.value,int) or isinstance(tree.value,float):\n",
    "        print str(tree.feature) + ' >= ' + str(tree.value) + ' ?'\n",
    "    else:\n",
    "        print str(tree.feature) + ' == ' + str(tree.value) + ' ?'\n",
    "    if tree.true_node:\n",
    "        print indent+'T:',\n",
    "        print_tree(tree.true_node, indent+'   ')\n",
    "    if tree.false_node:\n",
    "        print indent+'F:',\n",
    "        print_tree(tree.false_node,indent+'   ')\n",
    "\n",
    "print_tree(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring performance\n",
    "\n",
    "To measure our decision tree performance, we are going to split our dataset into three different sets:\n",
    "\n",
    "- A training set, which will be used to build the three\n",
    "- A validation set, which will be used to determine the best hyperparameters (in our case, the maximum depth of the three)\n",
    "- A test set, which will be used to measure the performance\n",
    "\n",
    "We will randomly construct the sets, and we will spit the sets with 60%, 20% and 20% of the data, respectively for the trainig, validation and test sets. Since decision trees are very prone to overfit, it is very important we get stratified samples from the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 600124\n",
      "Validation set size: 200041\n",
      "Test set size: 200044\n"
     ]
    }
   ],
   "source": [
    "def dataset_split(df, label_name, train_size=0.6, validation_size=0.2):\n",
    "    \"\"\"\n",
    "    splits the data into training, validation and test sets\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty dataframes\n",
    "    train_set = pd.DataFrame(columns=list(df.columns))\n",
    "    validation_set = pd.DataFrame(columns=list(df.columns))\n",
    "    test_set = pd.DataFrame(columns=list(df.columns))\n",
    "    \n",
    "    # stratify sampling\n",
    "    labels = df[label_name].unique()\n",
    "    for label in labels:\n",
    "        label_df = df.ix[df[label_name] == label]\n",
    "        label_df = label_df.sample(frac=1) #randomize\n",
    "        size = len(label_df.index)\n",
    "        validation_start = int(train_size*size)\n",
    "        test_start = int((train_size+validation_size)*size)\n",
    "        train_set = pd.concat([train_set, label_df[:validation_start]])\n",
    "        validation_set = pd.concat([validation_set, label_df[validation_start:test_start]])\n",
    "        test_set = pd.concat([test_set, label_df[test_start:]])\n",
    "    \n",
    "    # randomizing\n",
    "    train_set = train_set.sample(frac=1)\n",
    "    validation_set = validation_set.sample(frac=1)\n",
    "    test_set = test_set.sample(frac=1)\n",
    "    \n",
    "    return train_set, validation_set, test_set\n",
    "\n",
    "train_set, validation_set, test_set = dataset_split(data,'rating')\n",
    "\n",
    "print \"Training set size: \" + str(len(train_set.index))\n",
    "print \"Validation set size: \" + str(len(validation_set.index))\n",
    "print \"Test set size: \" + str(len(test_set.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(tree, row):\n",
    "    \n",
    "    if tree is None:\n",
    "        raise ValueError(\"tree must not be empty\")\n",
    "    if tree.true_node is None or tree.false_node is None:\n",
    "        return tree.counts.argmax()\n",
    "    if isinstance(tree.value,int) or isinstance(tree.value,float):\n",
    "        answer = (row[tree.feature] >= tree.value)\n",
    "    else:\n",
    "        answer = (row[tree.feature] == tree.value)\n",
    "    if answer:\n",
    "        return predict(tree.true_node, row)\n",
    "    return predict(tree.false_node, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score(tree, df, label_name):\n",
    "    \"\"\"\n",
    "    returns the accuracy and the confusion matrix for the classifier\n",
    "    in a given test set\n",
    "    \"\"\"\n",
    "    \n",
    "    # creating the confusion matrix\n",
    "    labels = df[label_name].unique()\n",
    "    confusion_matrix = {}\n",
    "    for label in labels:\n",
    "        label_dict = {}\n",
    "        for other_label in labels:\n",
    "            label_dict[other_label] = 0\n",
    "        confusion_matrix[label] = label_dict\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        prediction = predict(tree, row)\n",
    "        confusion_matrix[prediction][row[label_name]] += 1\n",
    "    \n",
    "    # compute accuracy\n",
    "    total = 0\n",
    "    rights = 0\n",
    "    for label in labels:\n",
    "        for other_label in labels:\n",
    "            total += confusion_matrix[label][other_label]\n",
    "        rights += confusion_matrix[label][label]\n",
    "    accuracy = float(rights)/total\n",
    "    \n",
    "    return confusion_matrix, accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best depth. This may take a while...\n",
      "Accuracy for depth = 1: 0.348898475812\n",
      "Accuracy for depth = 3: 0.350188211417\n",
      "Accuracy for depth = 5: 0.351307981864\n",
      "Accuracy for depth = 8: 0.354542318825\n",
      "Accuracy for depth = 12: 0.357226768512\n",
      "Accuracy for depth = 15: 0.358311546133\n"
     ]
    }
   ],
   "source": [
    "def find_best_depth(train_set, validation_set, depths):\n",
    "    \"\"\"\n",
    "    finds the depth that scores the most in the validation set\n",
    "    \"\"\"\n",
    "    print \"Finding best depth. This may take a while...\"\n",
    "    best_depth = None\n",
    "    best_tree = None\n",
    "    maximum_score = 0\n",
    "    for depth in depths:\n",
    "        tree = build_tree(train_set, 'rating', depth)\n",
    "        _, current_score = score(tree, validation_set, 'rating')\n",
    "        print \"Accuracy for depth = \" + str(depth) + \": \" + str(current_score)\n",
    "        if current_score > maximum_score:\n",
    "            best_depth = depth\n",
    "            best_tree = tree\n",
    "    return best_depth, best_tree\n",
    "\n",
    "best_depth, best_tree = find_best_depth(train_set, validation_set, [1,3,5,8,12,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
