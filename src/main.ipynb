{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Movie Rates with Decision Tree\n",
    "\n",
    "In this report, we are building step by step a decision tree to predict user ratings on movies using the MovieLens dataset, available at http://grouplens.org/datasets/movielens/\n",
    "\n",
    "The dataset is composed by 3 main files:\n",
    "\n",
    "**movies.dat:** this file contains information of all movies, in the format < movie id > :: < movie name > :: < pipe separeted list of genders >\n",
    "\n",
    "**users.dat:** this file contains information of all users, in the format < user id > :: < user gender > :: < user age > :: < ocupation > :: < zip code > \n",
    "\n",
    "**ratings.dat:** this file contains information of all ratings, in the format < user id > :: < movie id > :: < rating > :: < timestamp >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data\n",
    "\n",
    "#### Choosing features and building data frame\n",
    "\n",
    "The first step in this project is to join the data in the 3 data files into a feature and a label matrices. It is very important to carefully choose the attributes to build and train the tree.\n",
    "\n",
    "In our first approach, we will try to predict the rating without using explicitely the id of the movie and the id of the user. This is because, although they could be good criteria, the large amount of different values in those columns represent a great computational cost. The same goes to the user's zip code and timestamps. For those features, it is unlikely that they wield much relevant information. Finally, we will be using the genres of the movies. There are 17 genres (Action, Adventure, Animation, Children, Comedy, Documentary, Drama, Fantasy, Film-Noir, Horror, Musical, Mystery, Romance, Sci-Fi, Thriller, War and Western). We will store all that information in a single number, build with the binary representation of the movies genres. Since there are 17 different genres, we will be storing numbers from 0 to 2^17-1 = 131071. In practice, we expect a lot less different genre values (we will measure that later).\n",
    "\n",
    "The function **build_features** does all the processing, and returns the dataframe we will be using. The function **get_genre_id** takes a list of genres and returns its corresponding id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features. This may take a while...\n",
      "Done. Showint 5 first rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>ocupation</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating gender  age ocupation genre\n",
       "0       5      F    1        10    64\n",
       "1       5      M   56        16    64\n",
       "2       4      M   25        12    64\n",
       "3       4      M   25         7    64\n",
       "4       5      M   50         1    64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def get_genre_id(genres_list):\n",
    "    \"\"\"\n",
    "    return the integer id of a list of genres, \n",
    "    which is the integer corresponding to the binary intersection of the list with all the genres\n",
    "    \"\"\"\n",
    "    # movie genres\n",
    "    genres = [\n",
    "        'Action',\n",
    "        'Adventure',\n",
    "        'Animation',\n",
    "        'Children\\'s',\n",
    "        'Comedy',\n",
    "        'Documentary',\n",
    "        'Drama',\n",
    "        'Fantasy',\n",
    "        'Film-Noir',\n",
    "        'Horror',\n",
    "        'Musical',\n",
    "        'Mystery',\n",
    "        'Romance',\n",
    "        'Sci-Fi',\n",
    "        'Thriller',\n",
    "        'War',\n",
    "        'Western'\n",
    "    ]\n",
    "    # creating id\n",
    "    id = 0\n",
    "    weight = 1\n",
    "    for genre in genres:\n",
    "        if genre in genres_list:\n",
    "            id += weight\n",
    "        weight*=2\n",
    "    return str(id)\n",
    "    \n",
    "\n",
    "def build_features():\n",
    "    \"\"\"\n",
    "    read data from movies, users and rating and return a single pandas dataframe\n",
    "    of the joined tables, containing all info on ratings\n",
    "    \"\"\"\n",
    "    print \"Building features. This may take a while...\"\n",
    "    # reading movies data\n",
    "    movies_df = pd.DataFrame(columns=['movie_id', 'genre'])\n",
    "    with open('../data/movies.dat','r') as file:\n",
    "        lines = file.readlines()\n",
    "        for idx in range(len(lines)):\n",
    "            row = lines[idx].split(\"::\")\n",
    "            movie_genres = row[-1][:-1].split('|')\n",
    "            row = row[:-2] # ignore genre and movie name\n",
    "            row.append(get_genre_id(movie_genres)) # append genre id\n",
    "            movies_df.loc[idx] = row\n",
    "    \n",
    "    # reading users data\n",
    "    users_df = pd.read_table('../data/users.dat', \n",
    "                    names=['user_id', 'gender', 'age', 'ocupation', 'zip_code'], \n",
    "                     sep='::', engine='python')\n",
    "    users_df['user_id'] = users_df['user_id'].apply(lambda x: str(x))\n",
    "    users_df['ocupation'] = users_df['ocupation'].apply(lambda x: str(x))\n",
    "    \n",
    "    # reading ratings data\n",
    "    ratings_df = pd.read_table('../data/ratings.dat', \n",
    "                    names=['user_id', 'movie_id', 'rating', 'timestamp'], \n",
    "                    sep='::', engine='python')\n",
    "    ratings_df['movie_id'] = ratings_df['movie_id'].apply(lambda x: str(x))\n",
    "    ratings_df['user_id'] = ratings_df['user_id'].apply(lambda x: str(x))\n",
    "    \n",
    "    # join tables\n",
    "    user_ratings_df = ratings_df.merge(users_df, how='inner', on='user_id')\n",
    "    features_df = user_ratings_df.merge(movies_df, how='inner', on='movie_id')\n",
    "    \n",
    "    # drop unwanted features\n",
    "    features_df = features_df.drop('timestamp', 1)\n",
    "    features_df = features_df.drop('zip_code', 1)\n",
    "    features_df = features_df.drop('user_id', 1)\n",
    "    features_df = features_df.drop('movie_id', 1)\n",
    "   \n",
    "    # print first 5 rows\n",
    "    print \"Done. Showint 5 first rows:\"\n",
    "    display(features_df.head()) \n",
    "    \n",
    "    return features_df\n",
    "    \n",
    "data = build_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More about the data\n",
    "\n",
    "To better understand our data, let's take a look at the number of distinct values for each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct values of field rating: 5\n",
      "Number of distinct values of field gender: 2\n",
      "Number of distinct values of field age: 7\n",
      "Number of distinct values of field ocupation: 21\n",
      "Number of distinct values of field genre: 263\n"
     ]
    }
   ],
   "source": [
    "for feature in data.columns:\n",
    "    print \"Number of distinct values of field \" + feature + \":\",\n",
    "    print str(len(data[feature].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that should give as a decision tree with about 2*7*21*263 = 77322, which seems reasonable. We will now proceed to create the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Tree\n",
    "\n",
    "\n",
    "#### Splitting the dataset\n",
    "\n",
    "Now we are going to build the decision tree. To do so, we will start by creating a method that, given some data rows, a feature and a list of values, splits the data into disjoint subsets, according to the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_df(df, feature, values):\n",
    "    \"\"\"\n",
    "    splits a data frame into separate subsets, one for each value\n",
    "    each one corresponding to all the data which has df[feature] == value\n",
    "    \"\"\"\n",
    "    subsets = {}\n",
    "    for value in values:\n",
    "        local_df = df.ix[df[feature] == value]\n",
    "        subsets[value] = local_df\n",
    "        \n",
    "    return subsets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting labels\n",
    "\n",
    "We now construct a function to, given a dataframe, count how many rows are there of each label, which will be usefull for determining the nodes of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing how many ratings are for each number of stars:\n",
      "Number of  4 starts ratings: 348971\n",
      "Number of  3 starts ratings: 261197\n",
      "Number of  5 starts ratings: 226310\n",
      "Number of  2 starts ratings: 107557\n",
      "Number of  1 starts ratings: 56174\n"
     ]
    }
   ],
   "source": [
    "def label_counts(df, label_name):\n",
    "    \"\"\"\n",
    "    returns the count of each label value\n",
    "    \"\"\"\n",
    "    return df[label_name].value_counts()\n",
    "    \n",
    "print \"Printing how many ratings are for each number of stars:\"\n",
    "counts = label_counts(data, 'rating')\n",
    "for rating, count in counts.iteritems():\n",
    "    print \"Number of \", rating, \"starts ratings:\", str(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entropy\n",
    "\n",
    "We need to create a method for evaluating the homogenity of the set. We will use the standard entropy function for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial entropy is: 2.1002315644\n"
     ]
    }
   ],
   "source": [
    "from math import log \n",
    "log2 = lambda x: log(x)/log(2)\n",
    "\n",
    "def entropy(df, label_name):\n",
    "    \"\"\"\n",
    "    returns the entropy in a dataset\n",
    "    \"\"\"\n",
    "    s = 0.0\n",
    "    if len(df.index) == 0:\n",
    "        return s\n",
    "    \n",
    "    counts = label_counts(df, label_name)\n",
    "    size = len(df.index)\n",
    "    for _, count in counts.iteritems():\n",
    "        p = float(count)/size\n",
    "        s -= p*log2(p)\n",
    "    return s\n",
    "\n",
    "print \"Initial entropy is:\", entropy(data, 'rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the tree\n",
    "\n",
    "Now we start creating the tree. We use a recursive approach, building a node which maximizes the information gain at each step. Note that a node is represented by 3 attributes: the name of the feature, a list of the number of ratings for each class and a dictionary of the children nodes, where the keys are the values assumed by the feature. These variables are passed as parameters to the split_df method above written, dividing the dataset into disjoint subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class node:\n",
    "    \"\"\"\n",
    "    Tree node\n",
    "    \"\"\"\n",
    "    def __init__(self, feature, counts, children={}):\n",
    "        self.feature = feature\n",
    "        self.children = children\n",
    "        self.counts = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_best_criteria(df, label_name):\n",
    "    \"\"\"\n",
    "    build a node with a feature and a value \n",
    "    that maximizes information gain for the given dataframe\n",
    "    \"\"\"\n",
    "    # initial variables\n",
    "    best_criteria = None\n",
    "    best_gain = 0.0\n",
    "    best_sets = {}\n",
    "    current_entropy = entropy(df, label_name)\n",
    "    \n",
    "    # iterate through all possible choices and select the one with the biggest information gain\n",
    "    for feature in df.columns.values:\n",
    "        if feature != label_name:\n",
    "            # select different values\n",
    "            values = df[feature].unique()\n",
    "            # split data\n",
    "            subsets = split_df(df, feature, values)\n",
    "            # calculate entropy gain\n",
    "            gain = current_entropy\n",
    "            for value, subset in subsets.iteritems():\n",
    "                p = float(len(subset.index))/len(df.index)\n",
    "                gain -= p*entropy(subset, label_name)\n",
    "            # update if necessary\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_criteria = feature\n",
    "                best_sets = subsets\n",
    "    return best_criteria, best_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tree. This may take a while...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def build_tree(df, label_name, max_depth=None):\n",
    "    \"\"\"\n",
    "    build the decision tree\n",
    "    \"\"\"\n",
    "    if len(df.index) == 0 or max_depth == 0:\n",
    "        return None\n",
    "    feature, subsets = find_best_criteria(df, label_name)\n",
    "    if feature is None:\n",
    "        return None\n",
    "    new_depth = None if max_depth is None else max_depth-1\n",
    "    \n",
    "    children = {}\n",
    "    for value, subset in subsets.iteritems():\n",
    "        children[value] = build_tree(subset, label_name, new_depth)\n",
    "    return node(feature, label_counts(df, label_name), children)\n",
    "\n",
    "print \"Building tree. This may take a while...\"\n",
    "decision_tree = build_tree(data, 'rating', 2)\n",
    "print \"Done.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring performance\n",
    "\n",
    "To measure our decision tree performance, we are going to split our dataset into three different sets:\n",
    "\n",
    "- A training set, which will be used to build the three\n",
    "- A validation set, which will be used to determine the best hyperparameters (in our case, the maximum depth of the three)\n",
    "- A test set, which will be used to measure the performance\n",
    "\n",
    "We will randomly construct the sets, and we will spit the sets with 60%, 20% and 20% of the data, respectively for the trainig, validation and test sets. Since decision trees are very prone to overfit, it is very important we get stratified samples from the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 600124\n",
      "Validation set size: 200041\n",
      "Test set size: 200044\n"
     ]
    }
   ],
   "source": [
    "def dataset_split(df, label_name, train_size=0.6, validation_size=0.2):\n",
    "    \"\"\"\n",
    "    splits the data into training, validation and test sets\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty dataframes\n",
    "    train_set = pd.DataFrame(columns=list(df.columns))\n",
    "    validation_set = pd.DataFrame(columns=list(df.columns))\n",
    "    test_set = pd.DataFrame(columns=list(df.columns))\n",
    "    \n",
    "    # stratify sampling\n",
    "    labels = df[label_name].unique()\n",
    "    for label in labels:\n",
    "        label_df = df.ix[df[label_name] == label]\n",
    "        label_df = label_df.sample(frac=1) #randomize\n",
    "        size = len(label_df.index)\n",
    "        validation_start = int(train_size*size)\n",
    "        test_start = int((train_size+validation_size)*size)\n",
    "        train_set = pd.concat([train_set, label_df[:validation_start]])\n",
    "        validation_set = pd.concat([validation_set, label_df[validation_start:test_start]])\n",
    "        test_set = pd.concat([test_set, label_df[test_start:]])\n",
    "    \n",
    "    # randomizing\n",
    "    train_set = train_set.sample(frac=1)\n",
    "    validation_set = validation_set.sample(frac=1)\n",
    "    test_set = test_set.sample(frac=1)\n",
    "    \n",
    "    return train_set, validation_set, test_set\n",
    "\n",
    "train_set, validation_set, test_set = dataset_split(data,'rating')\n",
    "\n",
    "print \"Training set size: \" + str(len(train_set.index))\n",
    "print \"Validation set size: \" + str(len(validation_set.index))\n",
    "print \"Test set size: \" + str(len(test_set.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(tree, row):\n",
    "    \"\"\"\n",
    "    predict the result given a decision tree and a data row\n",
    "    \"\"\"\n",
    "    if tree is None:\n",
    "        raise ValueError(\"tree must not be empty\")\n",
    "    if not tree.children or row[tree.feature] not in tree.children or tree.children[row[tree.feature]] is None:\n",
    "        return tree.counts.argmax()\n",
    "    \n",
    "    return predict(tree.children[row[tree.feature]], row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score(tree, df, label_name):\n",
    "    \"\"\"\n",
    "    returns the accuracy and the confusion matrix for the classifier\n",
    "    in a given test set\n",
    "    \"\"\"\n",
    "    \n",
    "    # creating the confusion matrix\n",
    "    labels = df[label_name].unique()\n",
    "    confusion_matrix = {}\n",
    "    for label in labels:\n",
    "        label_dict = {}\n",
    "        for other_label in labels:\n",
    "            label_dict[other_label] = 0\n",
    "        confusion_matrix[label] = label_dict\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        prediction = predict(tree, row)\n",
    "        confusion_matrix[prediction][row[label_name]] += 1\n",
    "    \n",
    "    # compute accuracy\n",
    "    total = 0\n",
    "    rights = 0\n",
    "    for label in labels:\n",
    "        for other_label in labels:\n",
    "            total += confusion_matrix[label][other_label]\n",
    "        rights += confusion_matrix[label][label]\n",
    "    accuracy = float(rights)/total\n",
    "    \n",
    "    return confusion_matrix, accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best depth\n",
    "\n",
    "Using the validation set, we will now find the best depth for the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best depth. This may take a while...\n",
      "Accuracy for depth = 1: 0.348898475812\n",
      "Accuracy for depth = 2: 0.362110767293\n",
      "Accuracy for depth = 3: 0.357206772612\n",
      "Accuracy for depth = 4: 0.352727690823\n",
      "Best tree depth: 2\n",
      "Accuracy of best tree on test set: 0.360390714043\n"
     ]
    }
   ],
   "source": [
    "def find_best_depth(train_set, validation_set, depths):\n",
    "    \"\"\"\n",
    "    finds the depth that scores the most in the validation set\n",
    "    \"\"\"\n",
    "    print \"Finding best depth. This may take a while...\"\n",
    "    best_depth = None\n",
    "    best_tree = None\n",
    "    maximum_score = 0\n",
    "    for depth in depths:\n",
    "        tree = build_tree(train_set, 'rating', depth)\n",
    "        _, current_score = score(tree, validation_set, 'rating')\n",
    "        print \"Accuracy for depth = \" + str(depth) + \": \" + str(current_score)\n",
    "        if current_score > maximum_score:\n",
    "            maximum_score = current_score\n",
    "            best_depth = depth\n",
    "            best_tree = tree\n",
    "    return best_depth, best_tree\n",
    "\n",
    "best_depth, best_tree = find_best_depth(train_set, validation_set, [1,2,3,4])\n",
    "confusion_matrix, accuracy = score(best_tree, test_set, 'rating')\n",
    "\n",
    "print \"Best tree depth:\", best_depth\n",
    "print \"Accuracy of best tree on test set: \" + str(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting confusion matrix\n",
    "\n",
    "Now we plot the confusion matrix of the best tree, based on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAEoCAYAAAAdTumBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe8e4843190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(matrix_in, classes, cmap=plt.cm.Blues, is_dict = True):\n",
    "    if is_dict:\n",
    "        matrix = []\n",
    "        for s_class in classes:\n",
    "            row = []\n",
    "            for o_class in classes:\n",
    "                row.append(matrix_in[o_class][s_class])\n",
    "            matrix.append(row)\n",
    "        cm = np.array(matrix, dtype=int)\n",
    "    else:\n",
    "        cm = np.array(matrix_in, dtype=int)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks,classes)\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix, [1,2,3,4,5])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluating performance\n",
    "\n",
    "We built our decision tree using the maximization of the entorpy information gain as a criteria for splitting the data in each node. We trained our model using a training set corresponding to 60% of all the data, found the best depth using a validation set corresponding to 20% of all the data, and measured performance using the remaining 20% of the data. All sets were built using a stratified sampling approach to keep the ratio between classes approximately the same. \n",
    "\n",
    "As expected, large trees tend to produce overfitting, and small amounts underfitting. Using the validation set, we found that a good value for the maximum depth of the tree is 15. Lets see how the built classifier compares to the naive classifier that always guesses the label with the most ratings (which is 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = label_counts(data,'rating')\n",
    "best_guess = counts.argmax()\n",
    "labels = data['rating'].unique()\n",
    "\n",
    "naive_cm = np.zeros(shape=(5,5))\n",
    "for label in labels:\n",
    "    naive_cm[label-1][best_guess-1] = counts[label]\n",
    "\n",
    "plot_confusion_matrix(naive_cm, labels,is_dict = False)\n",
    "naive_accuracy = float(counts.max())/counts.sum()\n",
    "print \"Naive accuracy: \" + str(naive_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## A different aproach\n",
    "\n",
    "When we compare the results with the a priori classification, we see that we have only marginal improvements. We propose a different approach to construct the tree, so we can improve the results. The central idea is to make many binary decision trees, one for each movie. In this approach, we can drop al the genre features, which will save us some memory. The strategy of construction of the trees is the same as before, but with less features, since we will be using, for each tree, only thes features: **user gender**, **user age** and **user ocupation**.\n",
    "\n",
    "Lets build this second approach and see how it scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_data():\n",
    "    \"\"\"\n",
    "    read data from movies, users and rating and return a single pandas dataframe\n",
    "    of the joined tables, containing relevant info on ratings\n",
    "    \"\"\"\n",
    "    # reading users data\n",
    "    users_df = pd.read_table('../data/users.dat', \n",
    "                    names=['user_id', 'gender', 'age', 'ocupation', 'zip_code'], \n",
    "                     sep='::', engine='python')\n",
    "    users_df['user_id'] = users_df['user_id'].apply(lambda x: str(x))\n",
    "    users_df['ocupation'] = users_df['ocupation'].apply(lambda x: str(x))\n",
    "    \n",
    "    # reading ratings data\n",
    "    ratings_df = pd.read_table('../data/ratings.dat', \n",
    "                    names=['user_id', 'movie_id', 'rating', 'timestamp'], \n",
    "                    sep='::', engine='python')\n",
    "    ratings_df['movie_id'] = ratings_df['movie_id'].apply(lambda x: str(x))\n",
    "    ratings_df['user_id'] = ratings_df['user_id'].apply(lambda x: str(x))\n",
    "    \n",
    "    # join tables\n",
    "    features_df = ratings_df.merge(users_df, how='inner', on='user_id')\n",
    "    \n",
    "    # drop unwanted features\n",
    "    features_df = features_df.drop('timestamp', 1)\n",
    "    features_df = features_df.drop('zip_code', 1)\n",
    "    features_df = features_df.drop('user_id', 1)\n",
    "    \n",
    "    # print first 5 rows\n",
    "    display(features_df.head())\n",
    "    \n",
    "    return features_df\n",
    "\n",
    "data = build_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_subtrees(df,label_name, max_depth=None):\n",
    "    \"\"\"\n",
    "    build one binary tree for each movie and returns a dictionary of the trees\n",
    "    \"\"\"\n",
    "    \n",
    "    movie_ids = df['movie_id'].unique()\n",
    "    trees = {}\n",
    "    for movie_id in movie_ids:\n",
    "        local_df = df.ix[df['movie_id'] == movie_id]\n",
    "        local_df = local_df.drop('movie_id',1)\n",
    "        local_tree = build_tree(df, label_name, max_depth)\n",
    "        trees[movie_id] = local_tree\n",
    "    return trees\n",
    "    \n",
    "trees = build_subtrees(data, 'rating', 4)\n",
    "for movie_id, tree in trees:\n",
    "    print \"Tree for movie: \" + str(movie_id)\n",
    "    print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
